<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
	<TITLE>$titleTag</TITLE>
<STYLE type="text/css">
   subtoolbar {border-top-width: 0px; border-top-style: none;}


   
 </STYLE>	
</head>
<body>
	
	<table width="940" height="496" border="0" align="center" cellpadding="0" cellspacing="0">
		<tr>
			<td height="489" align="right" valign="top"><SPAN><BR><INPUT type="BUTTON" name="BUTTON" value="< BACK" onclick="javascript: history.go(-1)" /></SPAN><BR>
			<table width="100%">
				<tr valign="top" align="left" style="color:#0066FF">
					<th width="33%">j100658</th>
					<th width="33%">i27805209</th>
					<th width="33%"><A HREF='http://phoenix.jstor.org/Phoenix/toc/secure/issue.html?workType=mod&journalId=10.2307/j100658&issueId=10.2307_i27805209' target='_blank'>PHX Link</A></th>
				</tr>
			</table>
			<P align='left' style='color:#993300'><B><u>10.2307/27805217</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>The author introduces new statistics suited for testing uniformity of circular distributions and powerful against multimodal alternatives. One of them has a simple expression in terms of the geometric mean of the sample of chord lengths. The others belong to a family indexed by a continuous parameter. The asymptotic distributions under the null hypothesis are derived. We compare the power of the new tests against Stephens's alternatives with those of Ajne, Watson, and Hermans-Rasson's tests. Some of the new tests are the most powerful when the alternative has three or four modes. A heuristic justification of this feature is given. An application to the analysis of archaeological data is provided.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>The author introduces new statistics suited for testing uniformity of circular distributions and powerful against multimodal alternatives. One of them has a simple expression in terms of the geometric mean of the sample of chord lengths. The others belong to a family indexed by a continuous parameter. The asymptotic distributions under the null hypothesis are derived. We compare the power of the new tests against Stephens's alternatives with those of Ajne, Watson, and Hermans-Rasson's tests. Some of the new tests are the most powerful when the alternative has three or four modes. A heuristic justification of this feature is given. An application to the analysis of archaeological data is provided.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>L'auteur introduit de nouvelles statistiques permettant de tester l'uniformité d'une distribution circulaire et puissantes face aux alternatives multimodales. L'une d'elle admet une expression simple en fonction de la moyenne géométrique des longueurs des cordes de l'échantillon. Les autres appartiennent à une famille indexée par un paramètre continu. Les distributions asymptotiques sous l'hypothèse nulle sont données. Nous comparons la puissance des nouveaux tests dans le cas des hypothèses alternatives de Stephens avec celle des tests d'Ajne, Watson et Hermans-Rasson. Certains des nouveaux tests sont les plus puissants lorsque l'alternative présente trois ou quatre modes. Une explication heuristique de cette propriété est donnée. Nous appliquons le nouveau test à l'analyse de données archéologiques.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/27805218</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Testing for stochastic order among K populations is a common and important problem in statistical practice. It arises in the analysis of both planned experiments and observational studies. The authors develop a new nonparametric test for order among K populations that can accommodate any stochastic ordering. The test is based on a maximally selected chi-bar-square statistic. The authors find its limiting distribution and use simulations to derive critical values. Three important examples are used to illustrate the applicability of the general method. The authors find that the new tests outperform the existing methods in many practical cases.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Testing for stochastic order among K populations is a common and important problem in statistical practice. It arises in the analysis of both planned experiments and observational studies. The authors develop a new nonparametric test for order among K populations that can accommodate any stochastic ordering. The test is based on a maximally selected chi-bar-square statistic. The authors find its limiting distribution and use simulations to derive critical values. Three important examples are used to illustrate the applicability of the general method. The authors find that the new tests outperform the existing methods in many practical cases.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Vérifier l'ordonnancement stochastique de K populations est un problème statistique fréquent et important en pratique. Ceci se produit dans l'analyse d'expériences planifiées et d'observations cliniques. Les auteurs ont développé un nouveau test non paramétrique pour l'ordre dans K populations qui peut tenir compte de n'importe quel ordonnancement stochastique. Ce test est basé sur le choix de la statistique du khideux pondérée maximale. Les auteurs ont trouvé sa distribution asymptotique et ils utilisent des simulations pour obtenir les valeurs critiques. Trois exemples im-portants sont utilisés pour illuster l'applicabilité de la méthode générale. Les auteurs ont trouvé que le nouveau test surpasse les méthodes existantes dans beaucoup de cas pratiques.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/27805219</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>This paper is concerned with undoing aliasing effects, which arise from discretely sampling a continuous-time stochastic process. Such effects are manifested in the frequency-domain relationships between the sampled and original processes. The authors describe a general technique to undo aliasing effects, given two processes, one being a time-delayed version of the other. The technique is based on the observations that certain phase information between the two processes is unaffected by sampling, is completely determined by the (known) time delay, and contains sufficient information to undo aliasing effects. The authors illustrate their technique with a simulation example. The theoretical model is motivated by the helioseismological problem of determining modes of solar pressure waves. The authors apply their technique to solar radio data, and conclude that certain low-frequency modes known in the helioseismology literature are likely the result of aliasing effects.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>This paper is concerned with undoing aliasing effects, which arise from discretely sampling a continuous-time stochastic process. Such effects are manifested in the frequency-domain relationships between the sampled and original processes. The authors describe a general technique to undo aliasing effects, given two processes, one being a time-delayed version of the other. The technique is based on the observations that certain phase information between the two processes is unaffected by sampling, is completely determined by the (known) time delay, and contains sufficient information to undo aliasing effects. The authors illustrate their technique with a simulation example. The theoretical model is motivated by the helioseismological problem of determining modes of solar pressure waves. The authors apply their technique to solar radio data, and conclude that certain low-frequency modes known in the helioseismology literature are likely the result of aliasing effects.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Cet article porte sur des façons de réduire les effets du biais qui se produisent lorsque nous faisons échantillonnage discret d'un processus stochastique continu. De tels effets se manifestent dans les relations dans le domaine fréquentiel entre les processus original et échantillonné. Les auteurs décrivent une méthode générale réduisant les effets du biais à l'aide de deux processus, l'un étant une version à temps décalés de l'autre. La méthode est basée sur l'observation qu'une certaine information sur la phase entre les deux processus n'est pas affectée par l'échantillonnage, qu'elle est complètement déterminée par le délais temporel, qui est connu, et qu'elle contient suffisamment d'information pour annuler les effets du biais. Cette méthode est illustrée à l'aide d'un example simulé. Le modèle théorique est motivé par un problème d'héliosismologie qui consiste à déterminer les modes des ondes de pression solaires. Les auteurs appliquent leur technique à des données de radiofréquences solaires. Ils concluent que certains modes dans les basses fréquences connus dans la littérature héliosismologique proviennent vraisemblablement des effets du biais.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/27805220</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>The evaluation of new processor designs is an important issue in electrical and computer engineering. Architects use simulations to evaluate designs and to understand trade-offs and interactions among design parameters. However, due to the lengthy simulation time and limited resources, it is often practically impossible to simulate a full factorial design space. Effective sampling methods and predictive models are required. In this paper, the authors propose an automated performance predictive approach which employs an adaptive sampling scheme that interactively works with the predictive model to select samples for simulation. These samples are then used to build Bayesian additive regression trees, which in turn are used to predict the whole design space. Both real data analysis and simulation studies show that the method is effective in that, though sampling at very few design points, it generates highly accurate predictions on the unsampled points. Furthermore, the proposed model provides quantitative interpretation tools with which investigators can efficiently tune design parameters in order to improve processor performance.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>The evaluation of new processor designs is an important issue in electrical and computer engineering. Architects use simulations to evaluate designs and to understand trade-offs and interactions among design parameters. However, due to the lengthy simulation time and limited resources, it is often practically impossible to simulate a full factorial design space. Effective sampling methods and predictive models are required. In this paper, the authors propose an automated performance predictive approach which employs an adaptive sampling scheme that interactively works with the predictive model to select samples for simulation. These samples are then used to build Bayesian additive regression trees, which in turn are used to predict the whole design space. Both real data analysis and simulation studies show that the method is effective in that, though sampling at very few design points, it generates highly accurate predictions on the unsampled points. Furthermore, the proposed model provides quantitative interpretation tools with which investigators can efficiently tune design parameters in order to improve processor performance.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>L'évaluation de la conception de nouveaux processeurs est une étape importante en génie électrique et informatique. Les architectes utilisent des simulations afin d'évaluer les concepts et de comprendre les compromis et les interactions entre les différents paramètres du modèle de conception. Cependant, à cause de temps de simulation excessif et de la limitation des ressources, il est pratiquement impossible de simuler un devis factoriel complet. Des méthodes d'échantillonnage efficaces et des modèles de prédiction sont requis. Dans cet article, les auteurs proposent une approche automatique pour prédire la performance qui utilise un plan d'échantillonnage adaptatif interagissant avec le modèle prédictif pour choisir les échantillons lors de la simulation. Ces échantillons sont alors utilisés pour construire des arbres de régression bayésiens additifs qui sont à leur tour utilisés pour prédire l'ensemble de l'espace des devis. Des analyses de vraies données et des études de simulation ont montré que cette méthode est efficace. En effet, même si l'échantillonnage est fait sur très peu de points de devis, il génère des prédictions très précises sur les points non échantillonnés. De plus, le modèle proposé fournit des outils d'interprétation quantitatifs permettant aux chercheurs d'ajuster précisément les paramètres du devis afin d'améliorer les performances du processeur.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/27805221</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>A new family of mixture models for the model-based clustering of longitudinal data is introduced. The covariance structures of eight members of this new family of models are given and the associated maximum likelihood estimates for the parameters are derived via expectation–maximization (EM) algorithms. The Bayesian information criterion is used for model selection and a convergence criterion based on the Aitken acceleration is used to determine the convergence of these EM algorithms. This new family of models is applied to yeast sporulation time course data, where the models give good clustering performance. Further constraints are then imposed on the decomposition to allow a deeper investigation of the correlation structure of the yeast data. These constraints greatly extend this new family of models, with the addition of many parsimonious models.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>A new family of mixture models for the model-based clustering of longitudinal data is introduced. The covariance structures of eight members of this new family of models are given and the associated maximum likelihood estimates for the parameters are derived via expectation–maximization (EM) algorithms. The Bayesian information criterion is used for model selection and a convergence criterion based on the Aitken acceleration is used to determine the convergence of these EM algorithms. This new family of models is applied to yeast sporulation time course data, where the models give good clustering performance. Further constraints are then imposed on the decomposition to allow a deeper investigation of the correlation structure of the yeast data. These constraints greatly extend this new family of models, with the addition of many parsimonious models.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Nous présentons une nouvelle famille de modèles de mélanges de regroupement, à l'aide de modèles, pour des données longitudinales. La structure de covariance de huit membres de cette nouvelle famille de modèles est donnée et les estimateurs du maximum de vraisemblance associés aux paramètres sont obtenus en utilisant les algorithmes espérance-maximisation (EM). Le critère d'information bayésien (BIC) est utilisé pour choisir le modèle et un critère de convergence basé sur l'accélération d'Aitken est utilisé pour déterminer la convergence de ces algorithmes EM. Cette nouvelle famille de modèles est appliquée sur les données de décours temporel de la sporulation de levures. Ces modèles sont performants pour faire les regroupements. Des contraintes additionnelles sont aussi imposées sur la décomposition afin d'examiner en plus de profondeur la structure de corrélation dans des données de levures. Ces contraintes généralisent grandement cette nouvelle famille de modèles avec l'ajout de modèles plus parcimonieux.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/27805213</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>The performance of clinical tests for disease screening is often evaluated using the area under the receiver-operating characteristic (ROC) curve (AUC). Recent developments have extended the traditional setting to the AUC with binary time-varying failure status. Without considering covariates, our first theme is to propose a simple and easily computed nonparametric estimator for the time-dependent AUC. Moreover, we use generalized linear models with time-varying coefficients to characterize the time-dependent AUC as a function of covariate values. The corresponding estimation procedures are proposed to estimate the parameter functions of interest. The derived limiting Gaussian processes and the estimated asymptotic variances enable us to construct the approximated confidence regions for the AUCs. The finite sample properties of our proposed estimators and inference procedures are examined through extensive simulations. An analysis of the AIDS Clinical Trials Group (ACTG) 175 data is further presented to show the applicability of the proposed methods.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>The performance of clinical tests for disease screening is often evaluated using the area under the receiver-operating characteristic (ROC) curve (AUC). Recent developments have extended the traditional setting to the AUC with binary time-varying failure status. Without considering covariates, our first theme is to propose a simple and easily computed nonparametric estimator for the time-dependent AUC. Moreover, we use generalized linear models with time-varying coefficients to characterize the time-dependent AUC as a function of covariate values. The corresponding estimation procedures are proposed to estimate the parameter functions of interest. The derived limiting Gaussian processes and the estimated asymptotic variances enable us to construct the approximated confidence regions for the AUCs. The finite sample properties of our proposed estimators and inference procedures are examined through extensive simulations. An analysis of the AIDS Clinical Trials Group (ACTG) 175 data is further presented to show the applicability of the proposed methods.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>La performance des tests cliniques pour le dépistage de maladie est souvent évaluée en utilisant l'aire sous la courbe caractéristique de fonctionnements du récepteur (« ROC »), notée « AUC ». Des développements récents ont généralisé le cadre traditionnel à l'AUC avec un statut de panne binaire variant dans le temps. Sans considérer les covariables, nous commençons par proposer un estimateur non paramétrique pour l'AUC simple et facile à calculer. De plus, nous utilisons des modèles linéaires généralisés avec des coefficients dépendant du temps pour caractériser les AUC, dépendant du temps, comme fonction des covariables. Les procédures d'estimation asociées correspondantes sont proposées afin d'estimer les fonctions paramètres d'intérêt. Les processus gaussiens limites sont obtenus ainsi que les variances asymptotiques estimées afin de construire des régions de confiance approximatives pour les AUC. À l'aide de nombreuses simulations, les propriétés pour de petits échantillons des estimateurs proposés et des procédures d'inférence sont étudiées. Une analyse du groupe d'essais cliniques sur le sida 175 (ACTG 175) est aussi présentée afin de montrer l'applicabilité des méthodes proposées.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/27805214</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>The accuracy of a diagnostic test is typically characterized using the receiver operating characteristic (ROC) curve. Summarizing indexes such as the area under the ROC curve (AUC) are used to compare different tests as well as to measure the difference between two populations. Often additional information is available on some of the covariates which are known to influence the accuracy of such measures. The authors propose nonparametric methods for covariate adjustment of the AUC. Models with normal errors and possibly non-normal errors are discussed and analyzed separately. Nonparametric regression is used for estimating mean and variance functions in both scenarios. In the model that relaxes the assumption of normality, the authors propose a covariate-adjusted Mann–Whitney estimator for AUC estimation which effectively uses available data to construct working samples at any covariate value of interest and is computationally efficient for implementation. This provides a generalization of the Mann–Whitney approach for comparing two populations by taking covariate effects into account. The authors derive asymptotic properties for the AUC estimators in both settings, including asymptotic normality, optimal strong uniform convergence rates and mean squared error (MSE) consistency. The MSE of the AUC estimators was also assessed in smaller samples by simulation. Data from an agricultural study were used to illustrate the methods of analysis.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>The accuracy of a diagnostic test is typically characterized using the receiver operating characteristic (ROC) curve. Summarizing indexes such as the area under the ROC curve (AUC) are used to compare different tests as well as to measure the difference between two populations. Often additional information is available on some of the covariates which are known to influence the accuracy of such measures. The authors propose nonparametric methods for covariate adjustment of the AUC. Models with normal errors and possibly non-normal errors are discussed and analyzed separately. Nonparametric regression is used for estimating mean and variance functions in both scenarios. In the model that relaxes the assumption of normality, the authors propose a covariate-adjusted Mann–Whitney estimator for AUC estimation which effectively uses available data to construct working samples at any covariate value of interest and is computationally efficient for implementation. This provides a generalization of the Mann–Whitney approach for comparing two populations by taking covariate effects into account. The authors derive asymptotic properties for the AUC estimators in both settings, including asymptotic normality, optimal strong uniform convergence rates and mean squared error (MSE) consistency. The MSE of the AUC estimators was also assessed in smaller samples by simulation. Data from an agricultural study were used to illustrate the methods of analysis.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>La précision d'un test diagnostique est habituellement établie en utilisant les courbes caractéristiques de fonctionnement du récepteur (« ROC »). Des statistiques telles que l'aire sous la courbe ROC (« AUC \p=>>) sont utilisées afin de comparer différents tests et pour mesurer la différence entre deux populations. Souvent de l'information supplémentaire est disponible sur quelques covariables dont l'influence sur de telles statistiques est connue. Les auteurs suggèrent des méthodes non paramétriques afin d'ajuster la statistique AUC pour prendre en compte les covariables. Des modèles avec des erreurs gaussiennes et même non gaussiennes sont présentés et analysés séparément. Une régression non paramétrique est utilisée afin d'estimer les fonctions moyenne et variance dans les deux scénarios. Pour le modèle sans l'hypothèse de normalité, les auteurs proposent un estimateur de Mann-Whithney tenant compte des covariables pour l'AUC qui utilise l'information disponible dans les données afin de construire des échantillons d'analyse pour n'importe quelle valeur des covariables. Cet estimateur est implanté, car il est calculable de façon efficace. Il généralise l'approche de Mann-Whitney pour comparer deux populations en considérant l'effet des covariables. Les auteurs obtiennent les propriétés asymptotiques des estimateurs AUC pour les deux scénarios incluant la normalité asymptotique, les vitesses optimales de convergence uniforme forte et la convergence en erreur quadratique moyenne (« MSE »). Le MSE de l'estimateur de l'AUC est aussi étudié pour les petits échantillons à l'aide de simulations. Des données provenant d'une étude dans le domaine agricole sont utilisées afin d'illustrer les méthodes d'analyse.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/27805215</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Prior sensitivity analysis and cross-validation are important tools in Bayesian statistics. However, due to the computational expense of implementing existing methods, these techniques are rarely used. In this paper, the authors show how it is possible to use sequential Monte Carlo methods to create an efficient and automated algorithm to perform these tasks. They apply the algorithm to the computation of regularization path plots and to assess the sensitivity of the tuning parameter in g-prior model selection. They then demonstrate the algorithm in a cross-validation context and use it to select the shrinkage parameter in Bayesian regression.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Prior sensitivity analysis and cross-validation are important tools in Bayesian statistics. However, due to the computational expense of implementing existing methods, these techniques are rarely used. In this paper, the authors show how it is possible to use sequential Monte Carlo methods to create an efficient and automated algorithm to perform these tasks. They apply the algorithm to the computation of regularization path plots and to assess the sensitivity of the tuning parameter in g-prior model selection. They then demonstrate the algorithm in a cross-validation context and use it to select the shrinkage parameter in Bayesian regression.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>La sensibilité à la loi a priori et la validation croisée sont des outils importants des statistiques bayésiennes. Toutefois, ces techniques sont rarement utilisées en pratique car les méthodes disponibles pour les implémenter sont numériquement très coûteuses. Dans ce papier, les auteurs montrent comment il est possible d'utiliser les méthodes de Monte Carlo séquentielles pour obtenir un algorithme efficace et automatique pour implémenter ces techniques. Ils appliquent cet algorithme au calcul des chemins de régularisation pour un problème de régression et àla sensibilité du paramètre de la loi a priori de Zellner pour un problème de sèlection de variables. Ils appliquent ensuite cet algorithme pour la validation croisée et l'utilisent afin de sélectionner le paramètre de régularisation dans un problème de régression bayésienne.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/27805216</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>A new test for detecting a change in linear regression parameters assuming a general weakly dependent error structure is given. It extends earlier methods based on cumulative sums assuming independent errors. The novelty is in the new standardization method and in smoothing when the time series is dominated by high frequencies. Simulations show the excellent performance of the test. Examples are taken from environmental applications. The algorithm is easy to implement. Testing for multiple changes can be done by segmentation.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>A new test for detecting a change in linear regression parameters assuming a general weakly dependent error structure is given. It extends earlier methods based on cumulative sums assuming independent errors. The novelty is in the new standardization method and in smoothing when the time series is dominated by high frequencies. Simulations show the excellent performance of the test. Examples are taken from environmental applications. The algorithm is easy to implement. Testing for multiple changes can be done by segmentation.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Nous présentons un nouveau test pour détecter le changement dans les paramètres d'une régression linéaire en supposant une structure de dépendance faible sur les erreurs. Il généralise les méthodes précédentes qui sont basées sur les sommes cumulatives et qui supposent des erreurs indépendantes. La nouveauté réside dans la nouvelle méthode de standardisation et dans le lissage lorsque la série chronologique est dominée par les hautes fréquences. Des simulations illustrent l'excellente performance de ce test. Des exemples provenant d'applications environnementales sont aussi présentés. De plus, l'algorithme est facile à implanter. Un test pour des changements multiples peut être obtenu par segmentation.</TD></TR></table>
				
		</td>
		</tr>
	</table>		
</body>
</html>
