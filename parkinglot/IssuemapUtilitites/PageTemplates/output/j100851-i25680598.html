<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
	<TITLE>$titleTag</TITLE>
<STYLE type="text/css">
   subtoolbar {border-top-width: 0px; border-top-style: none;}


   
 </STYLE>	
</head>
<body>
	
	<table width="940" height="496" border="0" align="center" cellpadding="0" cellspacing="0">
		<tr>
			<td height="489" align="right" valign="top"><SPAN><BR><INPUT type="BUTTON" name="BUTTON" value="< BACK" onclick="javascript: history.go(-1)" /></SPAN><BR>
			<table width="100%">
				<tr valign="top" align="left" style="color:#0066FF">
					<th width="33%">j100851</th>
					<th width="33%">i25680598</th>
					<th width="33%"><A HREF='http://phoenix.jstor.org/Phoenix/toc/secure/issue.html?workType=mod&journalId=10.2307/j100851&issueId=10.2307_i25680598' target='_blank'>PHX Link</A></th>
				</tr>
			</table>
			<P align='left' style='color:#993300'><B><u>10.2307/25680605</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: The goal of many studies in environmental epidemiology is to assess the relationship between chemical exposure and disease outcome. Often various assays can be used to measure a particular environmental exposure, with some assays being more invasive or expensive than others.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: The goal of many studies in environmental epidemiology is to assess the relationship between chemical exposure and disease outcome. Often various assays can be used to measure a particular environmental exposure, with some assays being more invasive or expensive than others.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Methods: We consider the situation in which 2 assays can be used to measure an environmental exposure. The first assay has measurement error and is subject to a lower detection limit (LOD), and the second assay has less measurement error and is not subject to a lower LOD. In this situation, the first assay is less invasive or less expensive and is measured in all study participants, whereas the second assay is more invasive or more expensive and is only measured in a subset of individuals. We develop a flexible class of regression models that incorporates both sets of assay measurements and allows for continuous or binary outcomes. We explore different design strategies for selecting the subset of patients in whom to measure the second assay. One design strategy is to measure the second more invasive or expensive assay only when the first assay is below LOD. We compare these designs with a simple design in which the second assay is measured in a random subset of patients without regard to the results of the first assay.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>3</TD><TD width='5%' bordercolor='blue'>Results: We develop estimation approaches for these regression models. We demonstrate through simulations that there are efficiency advantages of measuring the second assay in at least a fraction of cases in which the first assay is above LOD. We illustrate the methodology by using data from a study examining the effect of environmental polychlorinated biphenyl exposure on the risk of endometriosis.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>4</TD><TD width='5%' bordercolor='blue'>Conclusion: The proposed methodology has good statistical properties and will be a useful methodological technique for studying the effect of exposure on outcome when exposure assays are subject to LOD.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/25680606</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Many laboratory assays measure biomarkers via a 2-stage process. Direct measurement yields relative measures that are subsequently transformed to the unit of interest by using a calibration experiment. The calibration experiment is performed within the main experiment and uses a validation set for which true values are known and relative values are measured by assays to estimate the relation between relative and absolute values. Immunoassays, polymerase chain reaction, and chromatographic approaches are among assays performed in this manner.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Many laboratory assays measure biomarkers via a 2-stage process. Direct measurement yields relative measures that are subsequently transformed to the unit of interest by using a calibration experiment. The calibration experiment is performed within the main experiment and uses a validation set for which true values are known and relative values are measured by assays to estimate the relation between relative and absolute values. Immunoassays, polymerase chain reaction, and chromatographic approaches are among assays performed in this manner.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Methods: For studies with multiple batches, data from more than a single calibration experiment are available. Conventionally, calibration of assays based on the standard curve is performed specific to each batch; the calibration experiment from each batch is used to calibrate each batch independently. This batch-specific approach incorporates batch variability but, due to the small number of calibration measurements in each batch, may not be best suited for this purpose.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>3</TD><TD width='5%' bordercolor='blue'>Results: Mixed-effects models have been described to address interassay variability and to provide a measure of quality assurance. Conversely, when interbatch variability is negligible, a model that does not incorporate batch effect may be used to estimate an overall calibration curve.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>4</TD><TD width='5%' bordercolor='blue'>Conclusion: We explore approaches for use of calibration data in studies with many batches. Using a real data example with biomarker and outcome information, we show that risk estimates may vary depending on the calibration approach used. We demonstrate the potential for bias when using simulations. Under minimal interbatch variability, as seen in our data, conventional batch-specific calibration does not best use information available in the data and results in attenuated risk estimates.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/25680607</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: The goal of the present study was to quantify the population-based background serum concentrations of 2,3,7,8-tetrachlorodibenzo-p-dioxin (TCDD) by using data from the reference population of the 2005 University of Michigan Dioxin Exposure Study (UMDES) and the 2003–2004 National Health and Nutrition Examination Survey (NHANES).</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: The goal of the present study was to quantify the population-based background serum concentrations of 2,3,7,8-tetrachlorodibenzo-p-dioxin (TCDD) by using data from the reference population of the 2005 University of Michigan Dioxin Exposure Study (UMDES) and the 2003–2004 National Health and Nutrition Examination Survey (NHANES).</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Methods: Multiple imputation was used to impute the serum TCDD concentrations below the limit of detection by combining the 2 data sources. The background mean, quartiles, and 95th percentile serum TCDD concentrations were estimated by age and sex by using linear and quantile regressions for complex survey data.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>3</TD><TD width='5%' bordercolor='blue'>Results: Any age- and sex-specific mean, quartiles, and 95th percentiles of background serum TCDD concentrations of study participants between ages 18 and 85 years can be estimated from the regressions for the UMDES reference population and the NHANES non-Hispanic white population. For example, for a 50-year-old man in the reference population of UMDES, the mean, quartiles, and 95th percentile serum TCDD concentrations are estimated to be 1.1, 0.6, 1.1, 1.8, and 3.3 parts per trillion, respectively. The study also shows that the UMDES reference population is a valid reference population for serum TCDD concentrations for other predominantly white populations in Michigan.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>4</TD><TD width='5%' bordercolor='blue'>Conclusion: The serum TCDD concentrations increased with age and increased more over age in women than in men, and hence estimation of background concentrations must be adjusted for age and sex. The methods and results discussed in this article have wide application in studies of the concentrations of chemicals in human serum and in environmental samples.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/25680608</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Understanding the health effects associated with environmental chemicals is challenging when individuals have concentrations at or below the laboratory limits of detection as well as when the values may round to zero or are presented in the form of 0 to substitute for missing values, which may result in many zeros in the database. Comparison of mean concentrations between individuals with and without disease necessitates estimation procedures that allow for data with many zero values. The main aim of this article is to propose and examine parametric and distribution-free methods for comparing data sets containing many zero observations. An important application of this approach is related to assessing environmental chemical concentrations and reproductive health.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Understanding the health effects associated with environmental chemicals is challenging when individuals have concentrations at or below the laboratory limits of detection as well as when the values may round to zero or are presented in the form of 0 to substitute for missing values, which may result in many zeros in the database. Comparison of mean concentrations between individuals with and without disease necessitates estimation procedures that allow for data with many zero values. The main aim of this article is to propose and examine parametric and distribution-free methods for comparing data sets containing many zero observations. An important application of this approach is related to assessing environmental chemical concentrations and reproductive health.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Methods: We extended the empirical likelihood technique for estimating confidence intervals (CIs) in data sets with many zeros. We examined the proposed empirical likelihood interval estimations via a broad Monte Carlo study that compares the proposed method with parametric techniques. Certain characteristics of Monte Carlo simulations were chosen to be close to parameters of the real data set. We applied the method to a cohort study comprising 84 women aged 18–40 years who had undergone laparoscopy between 1999 and 2000 in whom serum concentrations of 2 organochlorine pesticides—Aldrin and beta-Benzene hexachloride (?-BHC) were measured using gas chromatography with electron capture.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>3</TD><TD width='5%' bordercolor='blue'>Results: When applied to the cohort study, the method produced efficient 95% CIs, allowing for the comparison of mean serum Aldrin concentrations for women with and without endometriosis (0.000338, 0.003561) and (0.000803, 0.004211), respectively. Mean ?-BHC concentrations also could be compared (0.000493, 0.005869) and (0.000680, 0.003807) based on individuals with and without the disease, respectively. Differences in mean concentrations for Aldrin and ?-BHC could be estimated (–0.001563, 0.003025) and (–0.003522, 0.002890), respectively.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>4</TD><TD width='5%' bordercolor='blue'>Conclusions: We found the empirical likelihood method for estimating CIs robust when data sets contain many zeros. In so doing, mean concentrations of Aldrin or ?-BHC did not differ by endometriosis diagnosis.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/25680609</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Data with some values below a limit of detection (LOD) can be analyzed using methods of survival analysis for left-censored data. The reverse Kaplan-Meier (KM) estimator provides an effective method for estimating the distribution function and thus population percentiles for such data. Although developed in the 1970s and strongly advocated since then, it remains rarely used, partly due to limited software availability.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Data with some values below a limit of detection (LOD) can be analyzed using methods of survival analysis for left-censored data. The reverse Kaplan-Meier (KM) estimator provides an effective method for estimating the distribution function and thus population percentiles for such data. Although developed in the 1970s and strongly advocated since then, it remains rarely used, partly due to limited software availability.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Methods: In this paper, the reverse KM estimator is described and is illustrated using serum dioxin data from the University of Michigan Dioxin Exposure Study (UMDES) and the National Health and Nutrition Examination Survey (NHANES). Percentile estimates for left-censored data using the reverse KM estimator are compared with replacing values below the LOD with the LOD/2 or LOD/?2.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>3</TD><TD width='5%' bordercolor='blue'>Results: When some LODs are in the upper range of the complete values, and/or the percent censored is high, the different methods can yield quite different percentile estimates. The reverse KM estimator, which is the nonparametric maximum likelihood estimator, is the preferred method. Software options are discussed: The reverse KM can be calculated using software for the KM estimator. The JMP and SAS (SAS Institute, Cary, NC) and Minitab (Minitab, Inc, State College, PA), software packages calculate the reverse KM directly using their Turnbull estimator routines.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>4</TD><TD width='5%' bordercolor='blue'>Conclusion: The reverse KM estimator is recommended for estimation of the distribution function and population percentiles in preference to commonly used methods such as substituting LOD/2 or LOD/? for values below the LOD, assuming a known parametric distribution, or using imputation to replace the left-censored values.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/25680611</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Exploratory statistical analyses have been conducted on an epidemiologic data set in which the relationship was examined between exposure to polychlorinated biphenyl (PCB) mixtures and risk of endometriosis in women. In that study, the association between endometriosis and the sum of 4 antiestrogenic PCBs (PCBs 105, 114, 126, and 169) was borderline significant (P = 0.079), whereas an association was not found (P = 0.681) with the sum of 12 estrogenic PCBs. This finding was inconsistent with the widely held notion that endometriosis is an estrogen-dependent disease, prompting further statistical analyses to explore these associations in more detail.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Exploratory statistical analyses have been conducted on an epidemiologic data set in which the relationship was examined between exposure to polychlorinated biphenyl (PCB) mixtures and risk of endometriosis in women. In that study, the association between endometriosis and the sum of 4 antiestrogenic PCBs (PCBs 105, 114, 126, and 169) was borderline significant (P = 0.079), whereas an association was not found (P = 0.681) with the sum of 12 estrogenic PCBs. This finding was inconsistent with the widely held notion that endometriosis is an estrogen-dependent disease, prompting further statistical analyses to explore these associations in more detail.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Methods: As an alternative method of data reduction, an optimization algorithm was developed to determine weights in a linear combination of scaled PCB levels that has the strongest possible association with the risk of endometriosis.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>3</TD><TD width='5%' bordercolor='blue'>Results: Application of this method to the antiestrogenic PCB subgroup revealed that PCB 114 was responsible for nearly 100% of the association. The fact that PCB 114 is neither the most potent nor abundant antiestrogen in the mixture suggests that PCB 114 might be estrogenic or that the association may be driven by a different mechanism. Use of this statistical weighting method for further analyses of 12 estrogenic PCBs showed that any association with endometriosis was driven mainly by PCBs 99 and 188 and possibly a few others.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>4</TD><TD width='5%' bordercolor='blue'>Conclusion: Although the role of PCB mixtures in endometriosis remains unclear, these results demonstrate how the integration of refined statistical methods coupled with toxicologic and biologic interpretation can generate testable hypotheses that might not otherwise have been generated.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/25680601</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Problems in the analysis of laboratory data commonly arise in epidemiologic studies in which biomarkers subject to lower detection thresholds are used. Various thresholds exist including limit of detection (LOD), limit of quantification (LOQ), and limit of blank (LOB). Choosing appropriate strategies for dealing with data affected by such limits relies on proper understanding of the nature of the detection limit and its determination. In this paper, we demonstrate experimental and statistical procedures generally used for estimating different detection limits according to standard procedures in the context of analysis of fat-soluble vitamins and micronutrients in human serum.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Problems in the analysis of laboratory data commonly arise in epidemiologic studies in which biomarkers subject to lower detection thresholds are used. Various thresholds exist including limit of detection (LOD), limit of quantification (LOQ), and limit of blank (LOB). Choosing appropriate strategies for dealing with data affected by such limits relies on proper understanding of the nature of the detection limit and its determination. In this paper, we demonstrate experimental and statistical procedures generally used for estimating different detection limits according to standard procedures in the context of analysis of fat-soluble vitamins and micronutrients in human serum.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Methods: Fat-soluble vitamins and micronutrients were analyzed by high-performance liquid chromatography with diode array detection. A simulated serum matrix blank was repeatedly analyzed for determination of LOB parametrically by using the observed blank distribution as well as nonparametrically by using ranks. The LOD was determined by combining information regarding the LOB with data from repeated analysis of standard reference materials (SRMs), diluted to low levels; from LOB to 2–3 times LOB. The LOQ was determined experimentally by plotting the observed relative standard deviation (RSD) of SRM replicates compared with the concentration, where the LOQ is the concentration at an RSD of 20%.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>3</TD><TD width='5%' bordercolor='blue'>Results: Experimental approaches and example statistical procedures are given for determination of LOB, LOD, and LOQ. These quantities are reported for each measured analyte.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>4</TD><TD width='5%' bordercolor='blue'>Conclusion: For many analyses, there is considerable information available below the LOQ. Epidemiologic studies must understand the nature of these detection limits and how they have been estimated for appropriate treatment of affected data.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/25680602</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Raw data on the relationship between known and measured values of an analyte are collected and analyzed to determine the limit of quantification (LOQ) of an assay. In most LOQ problems, the researcher is given an observed value for the marker of interest if this value is greater than the LOQ, and a missing value (<LOQ) otherwise. From a statistical perspective, the implicit assumption is that there is no measurement error for values greater than the LOQ, and unacceptable measurement error for values less than the LOQ. A more plausible assumption is that there is measurement error throughout the measure's support.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Raw data on the relationship between known and measured values of an analyte are collected and analyzed to determine the limit of quantification (LOQ) of an assay. In most LOQ problems, the researcher is given an observed value for the marker of interest if this value is greater than the LOQ, and a missing value (<LOQ) otherwise. From a statistical perspective, the implicit assumption is that there is no measurement error for values greater than the LOQ, and unacceptable measurement error for values less than the LOQ. A more plausible assumption is that there is measurement error throughout the measure's support.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Methods: We describe a Bayesian measurement error model that yields prediction intervals for the true assay value throughout the range of analyte values, and allows for heteroscedasticity of the measurement errors.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>3</TD><TD width='5%' bordercolor='blue'>Results: We illustrate our model on calibration data for fat-soluble vitamins, focusing particularly on beta-cryptoxanthin. Prediction intervals for values above the LOQ are wide, and the width increases with the measured value. Prediction intervals below the LOQ provide more information than the statement that the value is less than the LOQ.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>4</TD><TD width='5%' bordercolor='blue'>Conclusion: The current approach to transmitting data from calibration assays is flawed, since it provides a distorted picture of the actual measurement error. Implications for subsequent analyses of assay measurements are discussed.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/25680603</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Linear regression with a left-censored independent variable X due to limit of detection (LOD) was recently considered by 2 groups of researchers: Richardson and Ciampi (Am J Epidemiol. 2003;157:355–363), and Schisterman et al (Am J Epidemiol. 2006;163:374–383).</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Linear regression with a left-censored independent variable X due to limit of detection (LOD) was recently considered by 2 groups of researchers: Richardson and Ciampi (Am J Epidemiol. 2003;157:355–363), and Schisterman et al (Am J Epidemiol. 2006;163:374–383).</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Methods: Both groups obtained consistent estimators for the regression slopes by replacing left-censored X with a constant, that is, the expectation of X given X below LOD E(X|X<LOD) in the former group and the sample mean of X given X above LOD in the latter.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>3</TD><TD width='5%' bordercolor='blue'>Results: Schisterman et al argued that their approach would be a better choice because the sample mean of X given X above LOD is available, whereas E(X|X<LOD) is unknown. Other substitution methods, such as replacing the left-censored values with LOD, or LOD/2, have been extensively used in the literature. Simulations were conducted to compare the performance under 2 scenarios in which the independent variable is normally and not normally distributed.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>4</TD><TD width='5%' bordercolor='blue'>Conclusion: Recommendations are given based on theoretical and simulation results. These recommendations are illustrated with one case study.</TD></TR></table><P align='left' style='color:#993300'><B><u>10.2307/25680604</u></B></P><BR><P align='left' style='color:#CC66FF'><B><u>Current Issuemap</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Highly active antiretroviral therapy (HAART) rapidly suppresses human immunodeficiency virus (HIV) viral replication and reduces circulating viral load, but the long-term effects of HAART on viral load remain unclear.</TD></TR></table><P align='left' style='color:#FF9900'><B><u>Most Eligible Issuemap Info</u></B></P><BR><table width='100%'><TR valign='top'><TD width='5%' bordercolor='blue'>1</TD><TD width='5%' bordercolor='blue'>Background: Highly active antiretroviral therapy (HAART) rapidly suppresses human immunodeficiency virus (HIV) viral replication and reduces circulating viral load, but the long-term effects of HAART on viral load remain unclear.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>2</TD><TD width='5%' bordercolor='blue'>Methods: We evaluated HIV viral load trajectories over 8 years following HAART initiation in the Multicenter AIDS Cohort Study and the Women's Interagency HIV Study. The study included 157 HIV-infected men and 199 HIV-infected women who were antiretroviral naive and contributed 1311 and 1837 semiannual personvisits post-HAART, respectively. To account for within-subject correlation and the high proportion of left-censored viral loads, we used a segmental Bernoulli/lognormal random effects model.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>3</TD><TD width='5%' bordercolor='blue'>Results: Approximately 3 months (0.30 years for men and 0.22 years for women) after HAART initiation, HIV viral loads were optimally suppressed (ie, with very low HIV RNA) for 44% (95% confidence interval = 39%–49%) of men and 43% (38%–47%) of women, whereas the other 56% of men and 57% of women had on average 2.1 (1.5–2.6) and 3.0 (2.7–3.2) log10 copies/mL, respectively.</TD></TR><TR valign='top'><TD width='5%' bordercolor='blue'>4</TD><TD width='5%' bordercolor='blue'>Conclusion: After 8 years on HAART, 75% of men and 80% of women had optimal suppression, whereas the rest of the men and women had suboptimal suppression with a median HIV RNA of 3.1 and 3.7 log10 copies/mL, respectively.</TD></TR></table>
				
		</td>
		</tr>
	</table>		
</body>
</html>
